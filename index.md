---
layout: page
title: Jerry Chee 
tagline: Department of Computer Science, Cornell University  
description: Jerry Chee McKinsey
---
![image](./assets/Jerry Chee.jpg){: height="256px" width="256px"}

**Email:** JerryChee [at] cs.cornell.edu

[//]: # ([CV](assets/JerryChee_CV.pdf))
[CV](assets/JerryChee_CV.pdf)

---

#### About
I am a first year Ph.D. student in Computer Science at Cornell University.
I am interested in stochastic optimization and statistical machine learning.


I was a Research Intern at the Baidu Cognitive Computing Lab in Bellevue, WA. 
Additionally, I've been working with [Panos Toulis](http://faculty.chicagobooth.edu/Panagiotis.toulis/) at UChicago Booth on statistically motivated topics in stochastic gradient descent (SGD). 

In my previous professional life I worked as a data scientist consultant at McKinsey & Company.
I graduated from the University of Chicago in 2017 with a degree in Computational and Applied Mathematics, with internships in data science at Nielsen and Uptake.

---

#### Working Papers
* Exact inference with stochastic gradient methods, with Panos Toulis
* Understanding and detecting convergence for stochastic gradient descent with momentum, with Ping Li

#### Publications
* [Convergence diagnostics for stochastic gradient descent with constant step size](https://arxiv.org/pdf/1710.06382), with Panos Toulis, AISTATS 2018, **<span style="color: black">oral presentation</span>**. \\
We focus on detecting the convergence of SGD with constant learning rate to its convergence phase.
Borrowing from the theory of stopping times in stochastic approximation, we developed a simple diagnostic that uses inner products of successive gradients to detect convergence. 
Theoretical and empirical results suggest that the diagnostic reliably detects the phase transition, which can speed up classical procedures.

---
#### Talks
* AISTATS, Lanzarote, Canary Islands, 2018 \\
Oral Presentation \\
Convergence Diagnostics for SGD with constant stepsize.

* JSM, Denver, USA, 2019 \\
Topic-contributed paper session \\
Statistical properties of stochastic gradient descent.
